{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<table style=\"width:100%\" align=\"center\" border=\"0px white\">\n",
    "<tr></td>\n",
    "<td><a href=\"https://colab.research.google.com/github/UCL-EO/uclgeog_msc_core/blob/master/NASA.ipynb\">\n",
    "         <img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\">\n",
    "</a>\n",
    "<td><a href=\"https://mybinder.org/v2/gh/UCL-EO/uclgeog_msc_core/master\">\n",
    "         <img alt=\"Binder\" src=\"https://mybinder.org/badge_logo.svg\">\n",
    "</a></td>                               \n",
    "<td><a href=\"https://github.com/UCL-EO/uclgeog_msc_core/blob/master/NASA.ipynb\">\n",
    "         <img alt=\"View in github\" src=\"https://img.shields.io/static/v1?logo=github&label=View%20in&message=github&color=green\">\n",
    "</a></td>    \n",
    "<td><a href=\"https://nbviewer.jupyter.org/github/UCL-EO/uclgeog_msc_core/blob/master/NASA.ipynb\">\n",
    "         <img alt=\"View in nbviewer\" src=\"https://img.shields.io/static/v1?logo=jupyter&label=View%20in&message=nbviewer&color=blue\">\n",
    "</a></td>    \n",
    "    </tr>\n",
    "    </table>\n",
    "    \n",
    "<img alt=\"UCL\" src=\"images/ucl_logo.png\">\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Code test\n",
    "\n",
    "\n",
    "## Purpose \n",
    "\n",
    "In this notebook, we will test codes from `uclgeog_msc_core` for downloading and displaying NASA images. We will also be introducing and viewing the NASA MODIS LAI product. This notebook should serve as an introduction to accessing such products from [`NASA EarthData`](https://urs.earthdata.nasa.gov).\n",
    "\n",
    "An additional purpose of this notebook is to test if the code associated with the setup of `uclgeog_msc_core` is working properly. \n",
    "\n",
    "We will also illustrate some of the things you will be able to do when you have finished this course. We use pre-generated codes in the library `uclgeog_msc_core` here, but in the course, we will *look under the bonnet* of such codes, and learn how to develop them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before you can use the material in this notebook, you will need to register as a user at the [`NASA EarthData`](https://urs.earthdata.nasa.gov/users/new).\n",
    "\n",
    "Once you have done that, make sure you know your `username` and `password` ready for below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "We will store your credentials for [`NASA EarthData`] (https://urs.earthdata.nasa.gov/users/new) to allow easier data downloading. \n",
    "\n",
    "**N.B. using `cylog().login()` is only intended to work with access to NASA Earthdata and to prevent you having to expose your username and password in these notes**.\n",
    "\n",
    "\n",
    "In the `uclgeog_msc_core` library, we have a Python class called `cylog`, written to allow easier persistent interface to NASA download servers.\n",
    "\n",
    "First, we import `cylog` from the `uclgeog_msc_core` library.\n",
    "\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uclgeog_msc.cylog import cylog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this gave an error, there is a problem importing the `uclgeog_msc_core` library and you shoiuld get help on this in a supoport class.\n",
    "\n",
    "Assuming that worked, we can look at the `help` method for this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class cylog in module uclgeog_msc.cylog:\n",
      "\n",
      "class cylog(builtins.object)\n",
      " |  cylog(init=False, destination_folder='.cylog')\n",
      " |  \n",
      " |  cylog provides a mechanism to partially hide username and\n",
      " |  password information that is required in plain text.\n",
      " |  \n",
      " |  It does this by storing a key and the encrypted version in\n",
      " |  a file accessible only to the user.\n",
      " |  \n",
      " |  Of course, when called (by the user) the (username, password)\n",
      " |  are exposed in plain text, so only use this when you \n",
      " |  have to enter plain text username/password information.\n",
      " |  \n",
      " |  It is written as a utility to allow UCL MSc students to \n",
      " |  show access to NASA Earthdata dataset download, without \n",
      " |  the need to expose (username, password) in a submitted report.\n",
      " |  \n",
      " |  Stores (in a dictionary in ~/{dest_path}/.cylog.npz) an\n",
      " |  encrypted form of username and password (and key)\n",
      " |  \n",
      " |  Uses cryptography.fernet.Fernet() for encryption\n",
      " |  \n",
      " |  cylog().login() : returns plain text tuple\n",
      " |                    (username, password)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, init=False, destination_folder='.cylog')\n",
      " |      Keyword arguments \n",
      " |      ----------\n",
      " |      init: bool\n",
      " |          to re-initialise the passord/username\n",
      " |          set to True. This will overwrite any existing password file.\n",
      " |      \n",
      " |      destination_folder: str\n",
      " |          The destination sub-folder, relative to ${HOME}.\n",
      " |          If this doesnt exist, it is created.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      when prompted, please supply:\n",
      " |      \n",
      " |      username: str\n",
      " |          The NASA EarthData username\n",
      " |      password: str\n",
      " |          The NASA EarthData password\n",
      " |  \n",
      " |  login(self)\n",
      " |      Reads encrypted information from ~/{dest_path}/.cylog.npz\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      A tuple containing plain text (username,password)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a description of what it does and how it works, and shows how useful good documentation can be in our code.\n",
    "\n",
    "Before you can use this, you will need to register at the [`NASA EarthData`](https://urs.earthdata.nasa.gov/users/new), as noted above. \n",
    "\n",
    "Make sure you know your `username` and `password` ready for below.\n",
    "\n",
    "### Earthdata login\n",
    "\n",
    "Run the cell below, and enter your `username` and `password` if prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = cylog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this call again, it should no longer pronmpt you, as it will read the stored credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = cylog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to force the code to let you re-enter your credentials (e.g. you got it wrong before, or have changed them), then change the call to:\n",
    "\n",
    "    cy = cylog(init=True)\n",
    "    \n",
    "and re-run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cylog` stores your username and password in a file that only you can read. We can use this as a convenient way to pull some NASA MODIS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS LAI product \n",
    "To introduce geospatial processing, we will use a dataset from the MODIS LAI product over the UK. \n",
    "\n",
    "You should note that the dataset you need to use for your assessed practical is a MODIS dataset with similar characteristics to the one in this example.\n",
    "\n",
    "The data product [MOD15](https://modis.gsfc.nasa.gov/data/dataprod/mod15.php) LAI/FPAR has been generated from NASA MODIS sensors Terra and Aqua data since 2002. We are now in dataset collection 6 (the data version to use).\n",
    "\n",
    "    LAI is defined as the one-sided green leaf area per unit ground area in broadleaf canopies and as half the total needle surface area per unit ground area in coniferous canopies. FPAR is the fraction of photosynthetically active radiation (400-700 nm) absorbed by green vegetation. Both variables are used for calculating surface photosynthesis, evapotranspiration, and net primary production, which in turn are used to calculate terrestrial energy, carbon, water cycle processes, and biogeochemistry of vegetation. Algorithm refinements have improved quality of retrievals and consistency with field measurements over all biomes, with a focus on woody vegetation.\n",
    "    \n",
    "We use such data to map and understand about the dynamics of terrestrial vegetation / carbon, for example, for climate studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raster data are arranged in tiles, indexed by row and column, to cover the globe:\n",
    "\n",
    "\n",
    "![MODIS tiles](https://www.researchgate.net/profile/J_Townshend/publication/220473201/figure/fig5/AS:277546596880390@1443183673583/The-global-MODIS-Sinusoidal-tile-grid.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "The pattern on the tile names is `hXXvYY` where `XX` is the horizontal coordinate and `YY` the vertical.\n",
    "\n",
    "\n",
    "* use the map above to work out the names of the two tiles that we will need to access data over the UK\n",
    "* set the variable `tiles` to contain these two names in a list\n",
    "\n",
    "For example, for the two tiles covering Madagascar, we would set:\n",
    "\n",
    "    tiles = ['h22v10','h22v11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2.2  Accessing NASA MODIS URLs\n",
    "\n",
    "Although you can access MODIS datasets through the [NASA Earthdata](https://urs.earthdata.nasa.gov/home) interface, there are many occasions that we would want to just automatically pull datasets. This is particularly true when you want a time series of data that might involve many files. For example, for analysing LAI or other variables over space/time) we will want to write code that pulls the time series of data. \n",
    "\n",
    "This is also something you will need to do the your assessed practical.\n",
    "\n",
    "If the data we want to use are accessible to us as a URL, we can use the python package [`requests`](https://www.tutorialspoint.com/downloading-files-from-web-using-python).\n",
    "\n",
    "Sometimes, we will be able to specify the parameters of the dataset we want, e.g. using [JSON](https://www.json.org). At othertimes (as in the case here) we might need to do a little work ourselves to construct the particular URL we want.\n",
    "\n",
    "If you visit the site [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006), you will see 'date' style links (e.g. `2018.09.30`) through to sub-directories. \n",
    "\n",
    "In these, e.g. [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/) you will find URLs of a set of files. \n",
    "\n",
    "The files pointed to by the URLs are the MODIS MOD15 4-day composite 500 m LAI/FPAR product [MCD15A3H](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mcd15a3h_v006).\n",
    "\n",
    "There are links to several datasets on the page, including 'quicklook files' that are jpeg format images of the datasets, e.g.:\n",
    "\n",
    "![MCD15A3H.A2018273.h17v03](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/BROWSE.MCD15A3H.A2018273.h17v03.006.2018278143630.1.jpg)\n",
    "\n",
    "as well as `xml` files and `hdf` datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date\n",
    "\n",
    "The URL we have used above, [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/) starts with a call to the server directory `MOTA`, so we can think of `https://e4ftl01.cr.usgs.gov/MOTA` as the base level URL.\n",
    "\n",
    "The rest of the directory information `MCD15A3H.006/2018.09.30` tells us:\n",
    "\n",
    "* the product name `MCD15A3H`\n",
    "* the product version `006`\n",
    "* the date of the dataset `2018.09.30`\n",
    "\n",
    "There are several ways we could specify the date information. The most 'human readable' is probably `YYYY.MM.DD` as given here. \n",
    "\n",
    "## MODIS filename format\n",
    "\n",
    "If we vist the link [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/), we see some files that have the suffix `hdf`.\n",
    "\n",
    "The `hdf` filenames are of the form:\n",
    "\n",
    "    MCD15A3H.A2018273.h35v10.006.2018278143650.hdf\n",
    "    \n",
    "where:\n",
    "\n",
    "* the first field (`MCD15A3H`) gives the product code\n",
    "* the second (`A2018273`) gives the observation date: day of year `273`, `2018` here\n",
    "* the third (`h35v10`) gives the 'MODIS tile' code for the data location\n",
    "* the remaining fields specify the product version number (`006`) and a code representing the processing date.\n",
    "\n",
    "If we want a particular dataset, we would assume then that we know the information to construct the first four fields.\n",
    "\n",
    "We then have the task remaining of finding an address of the pattern:\n",
    "\n",
    "    MCD15A3H.A2018273.h17v03.006.*.hdf\n",
    "    \n",
    "where `*` represents a wildcard (unknown element of the URL/filename).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "'''\n",
    "Get the world borders shapefile that we will need\n",
    "\n",
    "Python 3.5+:\n",
    "\n",
    "'''\n",
    "def get_world( borders_url = \"http://thematicmapping.org/downloads\",\\\n",
    "               file=\"TM_WORLD_BORDERS-0.3.zip\",\\\n",
    "               data='data',force=False):\n",
    "  '''\n",
    "  get borders shapefile and download to data\n",
    "  '''\n",
    "  tm_borders_url = borders_url + '/' + file\n",
    "  ofile = data + '/' + file\n",
    "  # mkdir\n",
    "  Path(data).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  if (not Path(ofile).exists()) or force:\n",
    "    try:\n",
    "      r = requests.get(tm_borders_url)\n",
    "      with open(ofile, 'wb') as fp:\n",
    "        fp.write (r.content)\n",
    "\n",
    "      shutil.unpack_archive(ofile,extract_dir=data)\n",
    "      return ofile\n",
    "    except:\n",
    "      return None\n",
    "  return ofile\n",
    "\n",
    "shp = get_world(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders_url = \"http://thematicmapping.org/downloads\"\n",
    "file=\"TM_WORLD_BORDERS-0.3.zip\"\n",
    "data='data'\n",
    "force=True\n",
    "tm_borders_url = borders_url + '/' + file\n",
    "ofile = data + '/' + file\n",
    "Path(data).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if (not Path(ofile).exists()) or force:\n",
    "    try:\n",
    "      r = requests.get(tm_borders_url)\n",
    "      with open(ofile, 'wb') as fp:\n",
    "        fp.write (r.content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_borders_url = 'http://thematicmapping.org/downloads/TM_WORLD_BORDERS-0.3.zip'\n",
    "\n",
    "r = requests.get(tm_borders_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<head><title>Not Acceptable!</title></head><body><h1>Not Acceptable!</h1><p>An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security.</p></body></html>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download\n",
    "\n",
    "Now we have some appreciation of the MODIS filename format, we can use some methods in `uclgeog_msc` to download some eaxmple datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# by inspecting the map above\n",
    "tiles = ['h17v03','h17v04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uclgeog_msc.get_modis_files import get_modis_files\n",
    "from uclgeog_msc.process_timeseries \\\n",
    "        import create_gdal_friendly_names,find_mcdfiles,mosaic_and_clip\n",
    "import matplotlib.pylab as plt\n",
    "import gdal\n",
    "# some libraries we need\n",
    "\n",
    "\n",
    "# UK tiles\n",
    "tiles = ['h17v03', 'h18v03']\n",
    "# specify day of year (DOY) and year\n",
    "doy,year = 1+10*8,2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD15A3H.A2020081.h17v03.006.2020086034006.hdf\n",
      "data/MCD15A3H.A2020081.h17v03.006.2020086034006.hdf exists\n",
      "MCD15A3H.A2020081.h18v03.006.2020086033548.hdf\n",
      "data/MCD15A3H.A2020081.h18v03.006.2020086033548.hdf exists\n",
      "failed to warp ['HDF4_EOS:EOS_GRID:\"data/MCD15A3H.A2020081.h17v03.006.2020086034006.hdf\":MOD_Grid_MCD15A3H:Lai_500m', 'HDF4_EOS:EOS_GRID:\"data/MCD15A3H.A2020081.h18v03.006.2020086033548.hdf\":MOD_Grid_MCD15A3H:Lai_500m'] 2020, 81, ['h17v03', 'h18v03'], data/\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# download files\n",
    "files = get_modis_files(doy,year,tiles,verbose=True,\\\n",
    "                        base_url='https://e4ftl01.cr.usgs.gov/MOTA/')\n",
    "mfiles = find_mcdfiles(year,doy,tiles,'data')\n",
    "\n",
    "fname = mosaic_and_clip(tiles,\n",
    "                    doy,\n",
    "                    year,\n",
    "                    folder=\"data/\",\n",
    "                    layer=\"Lai_500m\",\n",
    "                    shpfile=\"data/TM_WORLD_BORDERS-0.3.shp\",\n",
    "                    country_code=\"LU\")\n",
    "\n",
    "\n",
    "\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Chapter0_help.ipynb",
    "public": true
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "1.1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
